

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>License &mdash; valis &#34;1.2.0&#34;
 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=784e175d"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: black" >

          
          
          <a href="index.html">
            
              <img src="https://github.com/MathOnco/valis/raw/main/docs/_images/valis_logo_black_no_bg.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="registration.html">Registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="slide_io.html">Slide I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="preprocessing.html">Image pre-processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_detectors.html">Feature detectors and descriptors</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_matcher.html">Feature matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="affine_optimizer.html">Affine optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="micro_rigid_registrar.html">Micro-rigid registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="non_rigid_registrars.html">Non-rigid registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="serial_rigid.html">Serial rigid registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="serial_non_rigid.html">Serial non-rigid registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="viz.html">Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Change Log</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: black" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">valis</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">License</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/README.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <p><a class="reference external" href="https://valis.readthedocs.io/en/latest/?badge=latest"><img alt="Documentation Status" src="https://readthedocs.org/projects/valis/badge/?version=latest" /></a> <a class="reference external" href="https://github.com/MathOnco/valis/actions?workflow=CI"><img alt="CI Status" src="https://github.com/MathOnco/valis/workflows/CI/badge.svg?branch=main" /></a> <a class="reference external" href="https://badge.fury.io/py/valis-wsi"><img alt="pypi" src="https://badge.fury.io/py/valis-wsi.svg" /></a></p>
<a class="reference external image-reference" href="https://zenodo.org/badge/latestdoi/444523406"><img alt="https://zenodo.org/badge/444523406.svg" src="https://zenodo.org/badge/444523406.svg" />
</a>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<img alt="https://github.com/MathOnco/valis/raw/main/docs/_images/banner.gif" src="https://github.com/MathOnco/valis/raw/main/docs/_images/banner.gif" />
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<p>VALIS, which stands for Virtual Alignment of pathoLogy Image Series, is a fully automated pipeline to register whole slide images (WSI) using rigid and/or non-rigid transformtions. A full description of the method is described in the paper by <a class="reference external" href="https://www.nature.com/articles/s41467-023-40218-9">Gatenbee et al. 2023</a>. VALIS uses <a class="reference external" href="https://www.openmicroscopy.org/bio-formats/">Bio-Formats</a>, <a class="reference external" href="https://openslide.org/">OpenSlide</a>, <a class="reference external" href="https://www.libvips.org/">libvips</a>, and <a class="reference external" href="https://scikit-image.org/">scikit-image</a> to read images and slides, and so is able to work with over 300 image formats. Registered images can be saved as <a class="reference external" href="https://docs.openmicroscopy.org/ome-model/5.6.3/ome-tiff/">ome.tiff</a> slides that can be used in downstream analyses. ome.tiff format is opensource and widely supported, being readable in several different programming languages (Python, Java, Matlab, etc…) and software, such as <a class="reference external" href="https://qupath.github.io/">QuPath</a>, <a class="reference external" href="https://indicalab.com/halo/">HALO by Idica Labs</a>, etc…</p>
<p>The registration pipeline is fully automated and goes as follows:</p>
<blockquote>
<div><blockquote>
<div><img alt="https://github.com/MathOnco/valis/raw/main/docs/_images/pipeline.png" src="https://github.com/MathOnco/valis/raw/main/docs/_images/pipeline.png" />
</div></blockquote>
<ol class="arabic">
<li><p>Images/slides are converted to numpy arrays. As WSI are often too large to fit into memory, these images are usually lower resolution images from different pyramid levels.</p></li>
<li><p>Images are processed to single channel images. They are then normalized to make them look as similar as possible. Masks are then created to focus registration on the tissue.</p></li>
<li><p>Image features are detected and then matched between all pairs of image.</p></li>
<li><p>If the order of images is unknown, they will be optimally ordered based on their feature similarity. This increases the chances of successful registration because each image will be aligned to one that looks very similar.</p></li>
<li><p>Images will be aligned <em>towards</em> (not to) a reference image. If the reference image is not specified, it will automatically be set to the image at the center of the stack.</p></li>
<li><p>Rigid registration is performed serially, with each image being rigidly aligned towards the reference image. That is, if the reference image is the 5th in the stack, image 4 will be aligned to 5 (the reference), and then 3 will be aligned to the now registered version of 4, and so on. Only features found in both neighboring slides are used to align the image to the next one in the stack. VALIS uses feature detection to match and align images, but one can optionally perform a final step that maximizes the mutual information between each pair of images. This rigid registration can optionally be updated by matching features in higher resolution versions of the images (see <code class="code docutils literal notranslate"><span class="pre">micro_rigid_registrar.MicroRigidRegistrar</span></code>).</p></li>
<li><p>The registered rigid masks are combined to create a non-rigid registration mask. The bounding box of this mask is then used to extract higher resolution versions of the tissue from each slide. These higher resolution images are then processed as above and used for non-rigid registration, which is performed either by:</p>
<blockquote>
<div><ul class="simple">
<li><p>aligning each image towards the reference image following the same sequence used during rigid registration.</p></li>
<li><p>using groupwise registration that non-rigidly aligns the images to a common frame of reference. Currently this is only possible if <a class="reference external" href="https://simpleelastix.github.io">SimpleElastix</a> is installed.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>One can optionally perform a second non-rigid registration using an even higher resolution versions of each image. This is intended to better align micro-features not visible in the original images, and so is referred to as micro-registration. A mask can also be used to indicate where registration should take place.</p></li>
<li><p>Error is estimated by calculating the distance between registered matched features in the full resolution images.</p></li>
</ol>
</div></blockquote>
<p>The transformations found by VALIS can then be used to warp the full resolution slides. It is also possible to merge non-RGB registered slides to create a highly multiplexed image. These aligned and/or merged slides can then be saved as ome.tiff images. The transformations can also be use to warp point data, such as cell centroids, polygon vertices, etc…</p>
<p>In addition to registering images, VALIS provides tools to read slides using Bio-Formats and OpenSlide, which can be read at multiple resolutions and converted to numpy arrays or pyvips.Image objects. One can also slice regions of interest from these slides and warp annotated images. VALIS also provides functions to convert slides to the ome.tiff format, preserving the original metadata. Please see examples and documentation for more details.</p>
<p>Full documentation with installation instructions and examples can be found at <a class="reference external" href="https://valis.readthedocs.io/en/latest/">ReadTheDocs</a>.</p>
<section id="license">
<h1>License<a class="headerlink" href="#license" title="Link to this heading"></a></h1>
<p><a class="reference external" href="LICENSE.txt">MIT</a> © 2021-2024 Chandler Gatenbee</p>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022-2025, Chandler Gatenbee.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>